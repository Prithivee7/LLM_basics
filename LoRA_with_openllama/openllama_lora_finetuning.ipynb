{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "THIS IS THE NOTEBOOK THAT I USED FOR FINETUNING THE MODEL. PLEASE USE THIS NOTEBOOK FOR FOLLWING ALONG IN THE LECTURE."
      ],
      "metadata": {
        "id": "X89IGT5shl-h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0g2SAti6t_t",
        "outputId": "0e828b33-18ef-4e61-87c2-860fa8fd5f7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Aug 26 18:49:17 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   61C    P8    11W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### THIS COMMAND IS REQUIRED ONLY IF YOU WANT TO STORE YOUR TRAINED MODEL TO YOUR GOOGLE DRIVE.\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQyvla307BA8",
        "outputId": "d7ad1882-962b-42b9-9825-ec3594d8588b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a78yS2Fd7SEz",
        "outputId": "51a13ff0-60a9-445a-bad8-d2eeb0c46ffb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gdrive\tsample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/tloen/alpaca-lora.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bhqn_EBn7Ujq",
        "outputId": "7bc9039e-f620-4ab1-be48-fc35e7946436"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'alpaca-lora'...\n",
            "remote: Enumerating objects: 607, done.\u001b[K\n",
            "remote: Total 607 (delta 0), reused 0 (delta 0), pack-reused 607\u001b[K\n",
            "Receiving objects: 100% (607/607), 27.84 MiB | 18.81 MiB/s, done.\n",
            "Resolving deltas: 100% (357/357), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceDO5oGo7g-S",
        "outputId": "8be89e76-4bf8-4ef3-ae31-a30b9d5bb17e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alpaca-lora  gdrive  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd alpaca-lora"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjWDzaJ07k6C",
        "outputId": "719aea03-78de-41a0-d0e9-9b4922052ff2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/alpaca-lora\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59sDrMcC7oiE",
        "outputId": "2893f7a2-d3cf-43b0-a320-4ecd26cecde9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alpaca_data_cleaned_archive.json  generate.py\n",
            "alpaca_data_gpt4.json\t\t  lengths.ipynb\n",
            "alpaca_data.json\t\t  LICENSE\n",
            "DATA_LICENSE\t\t\t  pyproject.toml\n",
            "docker-compose.yml\t\t  README.md\n",
            "Dockerfile\t\t\t  requirements.txt\n",
            "export_hf_checkpoint.py\t\t  templates\n",
            "export_state_dict_checkpoint.py   utils\n",
            "finetune.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json"
      ],
      "metadata": {
        "id": "mdnCohFj8qTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_json(\"alpaca_data.json\")"
      ],
      "metadata": {
        "id": "CW7pOjzu8t19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "AfCcTfWa8yh9",
        "outputId": "74b18eb4-a352-4d08-c47b-4e3f72de9bac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             instruction  \\\n",
              "0                   Give three tips for staying healthy.   \n",
              "1                     What are the three primary colors?   \n",
              "2                     Describe the structure of an atom.   \n",
              "3                       How can we reduce air pollution?   \n",
              "4      Describe a time when you had to make a difficu...   \n",
              "...                                                  ...   \n",
              "51997  Generate an example of what a resume should li...   \n",
              "51998  Arrange the items given below in the order to ...   \n",
              "51999  Write an introductory paragraph about a famous...   \n",
              "52000  Generate a list of five things one should keep...   \n",
              "52001  Analyze the given legal document and explain t...   \n",
              "\n",
              "                                                   input  \\\n",
              "0                                                          \n",
              "1                                                          \n",
              "2                                                          \n",
              "3                                                          \n",
              "4                                                          \n",
              "...                                                  ...   \n",
              "51997                                                      \n",
              "51998                                   cake, me, eating   \n",
              "51999                                     Michelle Obama   \n",
              "52000                                                      \n",
              "52001  The following is an excerpt from a contract be...   \n",
              "\n",
              "                                                  output  \n",
              "0      1.Eat a balanced diet and make sure to include...  \n",
              "1      The three primary colors are red, blue, and ye...  \n",
              "2      An atom is made up of a nucleus, which contain...  \n",
              "3      There are a number of ways to reduce air pollu...  \n",
              "4      I had to make a difficult decision when I was ...  \n",
              "...                                                  ...  \n",
              "51997  Jean Tremaine\\n1234 Main Street, Anytown, CA 9...  \n",
              "51998                                     I eating cake.  \n",
              "51999  Michelle Obama is an inspirational woman who r...  \n",
              "52000  1. Research potential opportunities and carefu...  \n",
              "52001  This legal document states that Company A has ...  \n",
              "\n",
              "[52002 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c1438d10-77d0-4d9d-978d-ad3925b7bd16\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>instruction</th>\n",
              "      <th>input</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Give three tips for staying healthy.</td>\n",
              "      <td></td>\n",
              "      <td>1.Eat a balanced diet and make sure to include...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What are the three primary colors?</td>\n",
              "      <td></td>\n",
              "      <td>The three primary colors are red, blue, and ye...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Describe the structure of an atom.</td>\n",
              "      <td></td>\n",
              "      <td>An atom is made up of a nucleus, which contain...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>How can we reduce air pollution?</td>\n",
              "      <td></td>\n",
              "      <td>There are a number of ways to reduce air pollu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Describe a time when you had to make a difficu...</td>\n",
              "      <td></td>\n",
              "      <td>I had to make a difficult decision when I was ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51997</th>\n",
              "      <td>Generate an example of what a resume should li...</td>\n",
              "      <td></td>\n",
              "      <td>Jean Tremaine\\n1234 Main Street, Anytown, CA 9...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51998</th>\n",
              "      <td>Arrange the items given below in the order to ...</td>\n",
              "      <td>cake, me, eating</td>\n",
              "      <td>I eating cake.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51999</th>\n",
              "      <td>Write an introductory paragraph about a famous...</td>\n",
              "      <td>Michelle Obama</td>\n",
              "      <td>Michelle Obama is an inspirational woman who r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52000</th>\n",
              "      <td>Generate a list of five things one should keep...</td>\n",
              "      <td></td>\n",
              "      <td>1. Research potential opportunities and carefu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52001</th>\n",
              "      <td>Analyze the given legal document and explain t...</td>\n",
              "      <td>The following is an excerpt from a contract be...</td>\n",
              "      <td>This legal document states that Company A has ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>52002 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c1438d10-77d0-4d9d-978d-ad3925b7bd16')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c1438d10-77d0-4d9d-978d-ad3925b7bd16 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c1438d10-77d0-4d9d-978d-ad3925b7bd16');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d9269eea-c00b-424a-827e-133306286ee1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d9269eea-c00b-424a-827e-133306286ee1')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d9269eea-c00b-424a-827e-133306286ee1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ln7UpIbB89HM",
        "outputId": "d1886d35-0c1c-4147-e287-1adad48d8e01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52002"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_small = df[0:5000]"
      ],
      "metadata": {
        "id": "YcvOoCHi9Z2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_small.to_json('temp.json', orient='records')"
      ],
      "metadata": {
        "id": "PX7CA9UW9f4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEU6cZoV9l5G",
        "outputId": "9c7e9174-3cdd-4b44-851d-44b87cabaa1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alpaca_data_cleaned_archive.json  generate.py\n",
            "alpaca_data_gpt4.json\t\t  lengths.ipynb\n",
            "alpaca_data.json\t\t  LICENSE\n",
            "DATA_LICENSE\t\t\t  pyproject.toml\n",
            "docker-compose.yml\t\t  README.md\n",
            "Dockerfile\t\t\t  requirements.txt\n",
            "export_hf_checkpoint.py\t\t  temp.json\n",
            "export_state_dict_checkpoint.py   templates\n",
            "finetune.py\t\t\t  utils\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CuABZjGY9oFU",
        "outputId": "5e56cb2f-3b54-4dc3-809b-4bba7ef962c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/huggingface/peft.git (from -r requirements.txt (line 9))\n",
            "  Cloning https://github.com/huggingface/peft.git to /tmp/pip-req-build-smpt2z97\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git /tmp/pip-req-build-smpt2z97\n",
            "  Resolved https://github.com/huggingface/peft.git to commit 8c17d556a8fe9522e10d73d7bd3fad46a6ecae14\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting accelerate (from -r requirements.txt (line 1))\n",
            "  Downloading accelerate-0.22.0-py3-none-any.whl (251 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.2/251.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: appdirs in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (1.4.4)\n",
            "Collecting loralib (from -r requirements.txt (line 3))\n",
            "  Downloading loralib-0.1.1-py3-none-any.whl (8.8 kB)\n",
            "Collecting bitsandbytes (from -r requirements.txt (line 4))\n",
            "  Downloading bitsandbytes-0.41.1-py3-none-any.whl (92.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting black (from -r requirements.txt (line 5))\n",
            "  Downloading black-23.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m89.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets (from -r requirements.txt (line 7))\n",
            "  Downloading datasets-2.14.4-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.3/519.3 kB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fire (from -r requirements.txt (line 8))\n",
            "  Downloading fire-0.5.0.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting transformers>=4.28.0 (from -r requirements.txt (line 10))\n",
            "  Downloading transformers-4.32.0-py3-none-any.whl (7.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m102.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece (from -r requirements.txt (line 11))\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m76.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gradio (from -r requirements.txt (line 12))\n",
            "  Downloading gradio-3.41.2-py3-none-any.whl (20.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.1/20.1 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 1)) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 1)) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 1)) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 1)) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 1)) (2.0.1+cu118)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from black->-r requirements.txt (line 5)) (8.1.7)\n",
            "Collecting mypy-extensions>=0.4.3 (from black->-r requirements.txt (line 5))\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Collecting pathspec>=0.9.0 (from black->-r requirements.txt (line 5))\n",
            "  Downloading pathspec-0.11.2-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black->-r requirements.txt (line 5)) (3.10.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black->-r requirements.txt (line 5)) (2.0.1)\n",
            "Requirement already satisfied: ipython>=7.8.0 in /usr/local/lib/python3.10/dist-packages (from black->-r requirements.txt (line 5)) (7.34.0)\n",
            "Collecting tokenize-rt>=3.2.0 (from black->-r requirements.txt (line 5))\n",
            "  Downloading tokenize_rt-5.2.0-py2.py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 7)) (9.0.0)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets->-r requirements.txt (line 7))\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 7)) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 7)) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 7)) (4.66.1)\n",
            "Collecting xxhash (from datasets->-r requirements.txt (line 7))\n",
            "  Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets->-r requirements.txt (line 7))\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 7)) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 7)) (3.8.5)\n",
            "Collecting huggingface-hub<1.0.0,>=0.14.0 (from datasets->-r requirements.txt (line 7))\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire->-r requirements.txt (line 8)) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->-r requirements.txt (line 8)) (2.3.0)\n",
            "Collecting safetensors (from peft==0.6.0.dev0->-r requirements.txt (line 9))\n",
            "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers>=4.28.0->-r requirements.txt (line 10)) (3.12.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.28.0->-r requirements.txt (line 10)) (2023.6.3)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers>=4.28.0->-r requirements.txt (line 10))\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m78.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles<24.0,>=22.0 (from gradio->-r requirements.txt (line 12))\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 12)) (4.2.2)\n",
            "Collecting fastapi (from gradio->-r requirements.txt (line 12))\n",
            "  Downloading fastapi-0.103.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.2/66.2 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio->-r requirements.txt (line 12))\n",
            "  Downloading ffmpy-0.3.1.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==0.5.0 (from gradio->-r requirements.txt (line 12))\n",
            "  Downloading gradio_client-0.5.0-py3-none-any.whl (298 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.2/298.2 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx (from gradio->-r requirements.txt (line 12))\n",
            "  Downloading httpx-0.24.1-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 12)) (6.0.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 12)) (3.1.2)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 12)) (2.1.3)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 12)) (3.7.1)\n",
            "Collecting orjson~=3.0 (from gradio->-r requirements.txt (line 12))\n",
            "  Downloading orjson-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.9/139.9 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 12)) (9.4.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 12)) (2.2.1)\n",
            "Collecting pydub (from gradio->-r requirements.txt (line 12))\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart (from gradio->-r requirements.txt (line 12))\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version~=2.0 (from gradio->-r requirements.txt (line 12))\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 12)) (4.7.1)\n",
            "Collecting uvicorn>=0.14.0 (from gradio->-r requirements.txt (line 12))\n",
            "  Downloading uvicorn-0.23.2-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets<12.0,>=10.0 (from gradio->-r requirements.txt (line 12))\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 12)) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 12)) (4.19.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 12)) (0.12.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 7)) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 7)) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 7)) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 7)) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 7)) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 7)) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 7)) (1.3.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.8.0->black->-r requirements.txt (line 5)) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython>=7.8.0->black->-r requirements.txt (line 5))\n",
            "  Downloading jedi-0.19.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m88.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=7.8.0->black->-r requirements.txt (line 5)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=7.8.0->black->-r requirements.txt (line 5)) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.8.0->black->-r requirements.txt (line 5)) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.8.0->black->-r requirements.txt (line 5)) (3.0.39)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=7.8.0->black->-r requirements.txt (line 5)) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=7.8.0->black->-r requirements.txt (line 5)) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=7.8.0->black->-r requirements.txt (line 5)) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.8.0->black->-r requirements.txt (line 5)) (4.8.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 12)) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 12)) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 12)) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 12)) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 12)) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 12)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r requirements.txt (line 7)) (2023.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio->-r requirements.txt (line 12)) (0.5.0)\n",
            "Requirement already satisfied: pydantic-core==2.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio->-r requirements.txt (line 12)) (2.6.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->-r requirements.txt (line 7)) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->-r requirements.txt (line 7)) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->-r requirements.txt (line 7)) (2023.7.22)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate->-r requirements.txt (line 1)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate->-r requirements.txt (line 1)) (3.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate->-r requirements.txt (line 1)) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate->-r requirements.txt (line 1)) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate->-r requirements.txt (line 1)) (16.0.6)\n",
            "Collecting h11>=0.8 (from uvicorn>=0.14.0->gradio->-r requirements.txt (line 12))\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting starlette<0.28.0,>=0.27.0 (from fastapi->gradio->-r requirements.txt (line 12))\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpcore<0.18.0,>=0.15.0 (from httpx->gradio->-r requirements.txt (line 12))\n",
            "  Downloading httpcore-0.17.3-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio->-r requirements.txt (line 12)) (1.3.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio->-r requirements.txt (line 12)) (3.7.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=7.8.0->black->-r requirements.txt (line 5)) (0.8.3)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 12)) (2023.7.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 12)) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 12)) (0.9.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=7.8.0->black->-r requirements.txt (line 5)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.8.0->black->-r requirements.txt (line 5)) (0.2.6)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->httpcore<0.18.0,>=0.15.0->httpx->gradio->-r requirements.txt (line 12)) (1.1.3)\n",
            "Building wheels for collected packages: fire, peft, ffmpy\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116934 sha256=030f842c59528a75d8bc23e08ac94f960616577e078dd40df756f2a37dffb8ea\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/d4/f7/9404e5db0116bd4d43e5666eaa3e70ab53723e1e3ea40c9a95\n",
            "  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for peft: filename=peft-0.6.0.dev0-py3-none-any.whl size=85089 sha256=abbef239e68728aae41b17e14bf1e651e253cbb7d75a0db12aadb0e32dbafcb9\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-h9yv71i6/wheels/d7/c7/de/1368fac8590e1b103ddc2ec2a28ad51d83aded1a3830e8a087\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.1-py3-none-any.whl size=5579 sha256=de949fe016e9b1e28ff8b19f9a36f833fb0b54b446b0c87a4971170ce0bb25bb\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/a6/d1/1c0828c304a4283b2c1639a09ad86f83d7c487ef34c6b4a1bf\n",
            "Successfully built fire peft ffmpy\n",
            "Installing collected packages: tokenizers, sentencepiece, safetensors, pydub, ffmpy, bitsandbytes, xxhash, websockets, tokenize-rt, semantic-version, python-multipart, pathspec, orjson, mypy-extensions, loralib, jedi, h11, fire, dill, aiofiles, uvicorn, starlette, multiprocess, huggingface-hub, httpcore, black, transformers, httpx, fastapi, gradio-client, datasets, gradio, accelerate, peft\n",
            "Successfully installed accelerate-0.22.0 aiofiles-23.2.1 bitsandbytes-0.41.1 black-23.7.0 datasets-2.14.4 dill-0.3.7 fastapi-0.103.0 ffmpy-0.3.1 fire-0.5.0 gradio-3.41.2 gradio-client-0.5.0 h11-0.14.0 httpcore-0.17.3 httpx-0.24.1 huggingface-hub-0.16.4 jedi-0.19.0 loralib-0.1.1 multiprocess-0.70.15 mypy-extensions-1.0.0 orjson-3.9.5 pathspec-0.11.2 peft-0.6.0.dev0 pydub-0.25.1 python-multipart-0.0.6 safetensors-0.3.3 semantic-version-2.10.0 sentencepiece-0.1.99 starlette-0.27.0 tokenize-rt-5.2.0 tokenizers-0.13.3 transformers-4.32.0 uvicorn-0.23.2 websockets-11.0.3 xxhash-3.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python finetune.py \\\n",
        "    --base_model 'openlm-research/open_llama_3b_v2' \\\n",
        "    --data_path './temp.json' \\\n",
        "    --output_dir './lora-alpaca-temp' \\\n",
        "    --batch_size 16 \\\n",
        "    --micro_batch_size 16 \\\n",
        "    --num_epochs 2 \\\n",
        "    --learning_rate 1e-4 \\\n",
        "    --cutoff_len 512 \\\n",
        "    --val_set_size 2000 \\\n",
        "    --lora_r 8 \\\n",
        "    --lora_alpha 16 \\\n",
        "    --lora_dropout 0.05 \\\n",
        "    --lora_target_modules '[q_proj,v_proj]' \\\n",
        "    --train_on_inputs \\\n",
        "    --group_by_length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHC_R0Oq94mt",
        "outputId": "d0f7d4eb-5c98-4976-d562-f0e771a0ed0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-08-26 18:50:35.987985: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Training Alpaca-LoRA model with params:\n",
            "base_model: openlm-research/open_llama_3b_v2\n",
            "data_path: ./temp.json\n",
            "output_dir: ./lora-alpaca-temp\n",
            "batch_size: 16\n",
            "micro_batch_size: 16\n",
            "num_epochs: 2\n",
            "learning_rate: 0.0001\n",
            "cutoff_len: 512\n",
            "val_set_size: 2000\n",
            "lora_r: 8\n",
            "lora_alpha: 16\n",
            "lora_dropout: 0.05\n",
            "lora_target_modules: ['q_proj', 'v_proj']\n",
            "train_on_inputs: True\n",
            "add_eos_token: False\n",
            "group_by_length: True\n",
            "wandb_project: \n",
            "wandb_run_name: \n",
            "wandb_watch: \n",
            "wandb_log_model: \n",
            "resume_from_checkpoint: False\n",
            "prompt template: alpaca\n",
            "\n",
            "Downloading (…)lve/main/config.json: 100% 506/506 [00:00<00:00, 2.60MB/s]\n",
            "Downloading pytorch_model.bin: 100% 6.85G/6.85G [01:00<00:00, 113MB/s]\n",
            "Downloading (…)neration_config.json: 100% 137/137 [00:00<00:00, 625kB/s]\n",
            "Downloading tokenizer.model: 100% 512k/512k [00:00<00:00, 19.8MB/s]\n",
            "Downloading (…)cial_tokens_map.json: 100% 330/330 [00:00<00:00, 1.69MB/s]\n",
            "Downloading (…)okenizer_config.json: 100% 593/593 [00:00<00:00, 2.62MB/s]\n",
            "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=True`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/other.py:122: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
            "  warnings.warn(\n",
            "Downloading data files: 100% 1/1 [00:00<00:00, 8176.03it/s]\n",
            "Extracting data files: 100% 1/1 [00:00<00:00, 55.42it/s]\n",
            "Generating train split: 5000 examples [00:00, 40084.18 examples/s]\n",
            "trainable params: 2,662,400 || all params: 3,429,136,000 || trainable%: 0.07764054852300988\n",
            "Map: 100% 3000/3000 [00:03<00:00, 936.86 examples/s]\n",
            "Map: 100% 2000/2000 [00:02<00:00, 961.75 examples/s]\n",
            "  0% 0/376 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "{'loss': 1.9472, 'learning_rate': 9e-06, 'epoch': 0.05}\n",
            "{'loss': 2.1531, 'learning_rate': 1.9e-05, 'epoch': 0.11}\n",
            "{'loss': 2.3054, 'learning_rate': 2.9e-05, 'epoch': 0.16}\n",
            "{'loss': 2.3539, 'learning_rate': 3.9000000000000006e-05, 'epoch': 0.21}\n",
            "{'loss': 1.9843, 'learning_rate': 4.9e-05, 'epoch': 0.27}\n",
            "{'loss': 1.5552, 'learning_rate': 5.9e-05, 'epoch': 0.32}\n",
            "{'loss': 1.2733, 'learning_rate': 6.9e-05, 'epoch': 0.37}\n",
            "{'loss': 0.9214, 'learning_rate': 7.900000000000001e-05, 'epoch': 0.43}\n",
            "{'loss': 0.7861, 'learning_rate': 8.900000000000001e-05, 'epoch': 0.48}\n",
            "{'loss': 1.1334, 'learning_rate': 9.8e-05, 'epoch': 0.53}\n",
            "{'loss': 1.1352, 'learning_rate': 9.710144927536232e-05, 'epoch': 0.59}\n",
            "{'loss': 0.9174, 'learning_rate': 9.347826086956522e-05, 'epoch': 0.64}\n",
            "{'loss': 0.7142, 'learning_rate': 8.985507246376813e-05, 'epoch': 0.69}\n",
            "{'loss': 0.8273, 'learning_rate': 8.623188405797103e-05, 'epoch': 0.74}\n",
            "{'loss': 1.2255, 'learning_rate': 8.260869565217392e-05, 'epoch': 0.8}\n",
            "{'loss': 1.0145, 'learning_rate': 7.898550724637681e-05, 'epoch': 0.85}\n",
            "{'loss': 0.834, 'learning_rate': 7.536231884057971e-05, 'epoch': 0.9}\n",
            "{'loss': 0.704, 'learning_rate': 7.17391304347826e-05, 'epoch': 0.96}\n",
            "{'loss': 0.8711, 'learning_rate': 6.811594202898552e-05, 'epoch': 1.01}\n",
            "{'loss': 1.2071, 'learning_rate': 6.449275362318841e-05, 'epoch': 1.06}\n",
            " 53% 200/376 [21:38<22:57,  7.83s/it]\n",
            "  0% 0/250 [00:00<?, ?it/s]\u001b[A\n",
            "  1% 2/250 [00:00<00:58,  4.28it/s]\u001b[A\n",
            "  1% 3/250 [00:01<02:23,  1.72it/s]\u001b[A\n",
            "  2% 4/250 [00:02<02:15,  1.81it/s]\u001b[A\n",
            "  2% 5/250 [00:02<02:46,  1.48it/s]\u001b[A\n",
            "  2% 6/250 [00:03<02:51,  1.43it/s]\u001b[A\n",
            "  3% 7/250 [00:04<03:21,  1.20it/s]\u001b[A\n",
            "  3% 8/250 [00:06<04:08,  1.03s/it]\u001b[A\n",
            "  4% 9/250 [00:06<03:34,  1.12it/s]\u001b[A\n",
            "  4% 10/250 [00:07<03:04,  1.30it/s]\u001b[A\n",
            "  4% 11/250 [00:08<03:05,  1.29it/s]\u001b[A\n",
            "  5% 12/250 [00:08<02:47,  1.42it/s]\u001b[A\n",
            "  5% 13/250 [00:09<03:14,  1.22it/s]\u001b[A\n",
            "  6% 14/250 [00:10<03:17,  1.20it/s]\u001b[A\n",
            "  6% 15/250 [00:11<03:33,  1.10it/s]\u001b[A\n",
            "  6% 16/250 [00:12<03:35,  1.08it/s]\u001b[A\n",
            "  7% 17/250 [00:13<03:32,  1.10it/s]\u001b[A\n",
            "  7% 18/250 [00:14<03:03,  1.27it/s]\u001b[A\n",
            "  8% 19/250 [00:14<02:58,  1.29it/s]\u001b[A\n",
            "  8% 20/250 [00:16<03:32,  1.08it/s]\u001b[A\n",
            "  8% 21/250 [00:17<03:32,  1.08it/s]\u001b[A\n",
            "  9% 22/250 [00:17<03:09,  1.20it/s]\u001b[A\n",
            "  9% 23/250 [00:18<03:10,  1.19it/s]\u001b[A\n",
            " 10% 24/250 [00:19<03:06,  1.21it/s]\u001b[A\n",
            " 10% 25/250 [00:19<02:43,  1.37it/s]\u001b[A\n",
            " 10% 26/250 [00:20<02:37,  1.42it/s]\u001b[A\n",
            " 11% 27/250 [00:21<02:45,  1.35it/s]\u001b[A\n",
            " 11% 28/250 [00:21<02:43,  1.36it/s]\u001b[A\n",
            " 12% 29/250 [00:22<02:37,  1.40it/s]\u001b[A\n",
            " 12% 30/250 [00:23<02:31,  1.46it/s]\u001b[A\n",
            " 12% 31/250 [00:23<02:31,  1.45it/s]\u001b[A\n",
            " 13% 32/250 [00:24<02:28,  1.47it/s]\u001b[A\n",
            " 13% 33/250 [00:25<02:26,  1.48it/s]\u001b[A\n",
            " 14% 34/250 [00:25<02:25,  1.49it/s]\u001b[A\n",
            " 14% 35/250 [00:26<02:37,  1.37it/s]\u001b[A\n",
            " 14% 36/250 [00:27<02:43,  1.31it/s]\u001b[A\n",
            " 15% 37/250 [00:28<03:11,  1.11it/s]\u001b[A\n",
            " 15% 38/250 [00:30<03:40,  1.04s/it]\u001b[A\n",
            " 16% 39/250 [00:30<03:21,  1.05it/s]\u001b[A\n",
            " 16% 40/250 [00:32<03:28,  1.01it/s]\u001b[A\n",
            " 16% 41/250 [00:32<03:12,  1.09it/s]\u001b[A\n",
            " 17% 42/250 [00:33<02:58,  1.16it/s]\u001b[A\n",
            " 17% 43/250 [00:34<02:42,  1.28it/s]\u001b[A\n",
            " 18% 44/250 [00:34<02:31,  1.36it/s]\u001b[A\n",
            " 18% 45/250 [00:35<02:19,  1.46it/s]\u001b[A\n",
            " 18% 46/250 [00:36<02:21,  1.44it/s]\u001b[A\n",
            " 19% 47/250 [00:36<02:34,  1.31it/s]\u001b[A\n",
            " 19% 48/250 [00:37<02:35,  1.30it/s]\u001b[A\n",
            " 20% 49/250 [00:38<02:24,  1.39it/s]\u001b[A\n",
            " 20% 50/250 [00:39<02:51,  1.17it/s]\u001b[A\n",
            " 20% 51/250 [00:40<03:04,  1.08it/s]\u001b[A\n",
            " 21% 52/250 [00:41<02:50,  1.16it/s]\u001b[A\n",
            " 21% 53/250 [00:41<02:32,  1.29it/s]\u001b[A\n",
            " 22% 54/250 [00:43<02:57,  1.10it/s]\u001b[A\n",
            " 22% 55/250 [00:43<02:47,  1.16it/s]\u001b[A\n",
            " 22% 56/250 [00:44<02:26,  1.32it/s]\u001b[A\n",
            " 23% 57/250 [00:44<02:15,  1.42it/s]\u001b[A\n",
            " 23% 58/250 [00:45<02:21,  1.36it/s]\u001b[A\n",
            " 24% 59/250 [00:46<02:34,  1.24it/s]\u001b[A\n",
            " 24% 60/250 [00:48<03:00,  1.05it/s]\u001b[A\n",
            " 24% 61/250 [00:48<02:51,  1.11it/s]\u001b[A\n",
            " 25% 62/250 [00:49<02:49,  1.11it/s]\u001b[A\n",
            " 25% 63/250 [00:50<02:32,  1.23it/s]\u001b[A\n",
            " 26% 64/250 [00:50<02:11,  1.41it/s]\u001b[A\n",
            " 26% 65/250 [00:51<02:14,  1.37it/s]\u001b[A\n",
            " 26% 66/250 [00:52<02:10,  1.41it/s]\u001b[A\n",
            " 27% 67/250 [00:52<02:11,  1.39it/s]\u001b[A\n",
            " 27% 68/250 [00:53<02:15,  1.34it/s]\u001b[A\n",
            " 28% 69/250 [00:54<02:37,  1.15it/s]\u001b[A\n",
            " 28% 70/250 [00:55<02:24,  1.25it/s]\u001b[A\n",
            " 28% 71/250 [00:56<02:44,  1.09it/s]\u001b[A\n",
            " 29% 72/250 [00:57<02:29,  1.19it/s]\u001b[A\n",
            " 29% 73/250 [00:58<02:16,  1.30it/s]\u001b[A\n",
            " 30% 74/250 [00:58<02:10,  1.35it/s]\u001b[A\n",
            " 30% 75/250 [00:59<02:19,  1.25it/s]\u001b[A\n",
            " 30% 76/250 [01:00<02:28,  1.17it/s]\u001b[A\n",
            " 31% 77/250 [01:01<02:51,  1.01it/s]\u001b[A\n",
            " 31% 78/250 [01:02<02:26,  1.18it/s]\u001b[A\n",
            " 32% 79/250 [01:03<02:34,  1.11it/s]\u001b[A\n",
            " 32% 80/250 [01:04<02:21,  1.20it/s]\u001b[A\n",
            " 32% 81/250 [01:04<02:18,  1.22it/s]\u001b[A\n",
            " 33% 82/250 [01:05<02:13,  1.26it/s]\u001b[A\n",
            " 33% 83/250 [01:06<02:07,  1.31it/s]\u001b[A\n",
            " 34% 84/250 [01:06<01:57,  1.42it/s]\u001b[A\n",
            " 34% 85/250 [01:07<01:55,  1.43it/s]\u001b[A\n",
            " 34% 86/250 [01:08<02:13,  1.23it/s]\u001b[A\n",
            " 35% 87/250 [01:09<02:08,  1.27it/s]\u001b[A\n",
            " 35% 88/250 [01:10<02:02,  1.32it/s]\u001b[A\n",
            " 36% 89/250 [01:11<02:27,  1.10it/s]\u001b[A\n",
            " 36% 90/250 [01:12<02:27,  1.09it/s]\u001b[A\n",
            " 36% 91/250 [01:12<02:10,  1.21it/s]\u001b[A\n",
            " 37% 92/250 [01:13<02:08,  1.23it/s]\u001b[A\n",
            " 37% 93/250 [01:14<02:16,  1.15it/s]\u001b[A\n",
            " 38% 94/250 [01:15<02:21,  1.10it/s]\u001b[A\n",
            " 38% 95/250 [01:16<02:18,  1.12it/s]\u001b[A\n",
            " 38% 96/250 [01:17<02:08,  1.20it/s]\u001b[A\n",
            " 39% 97/250 [01:18<02:08,  1.19it/s]\u001b[A\n",
            " 39% 98/250 [01:18<02:04,  1.22it/s]\u001b[A\n",
            " 40% 99/250 [01:19<02:07,  1.19it/s]\u001b[A\n",
            " 40% 100/250 [01:20<02:01,  1.24it/s]\u001b[A\n",
            " 40% 101/250 [01:21<01:54,  1.30it/s]\u001b[A\n",
            " 41% 102/250 [01:22<02:02,  1.21it/s]\u001b[A\n",
            " 41% 103/250 [01:22<01:54,  1.28it/s]\u001b[A\n",
            " 42% 104/250 [01:23<01:40,  1.45it/s]\u001b[A\n",
            " 42% 105/250 [01:24<01:45,  1.37it/s]\u001b[A\n",
            " 42% 106/250 [01:24<01:44,  1.38it/s]\u001b[A\n",
            " 43% 107/250 [01:26<02:13,  1.07it/s]\u001b[A\n",
            " 43% 108/250 [01:27<02:08,  1.10it/s]\u001b[A\n",
            " 44% 109/250 [01:27<01:55,  1.22it/s]\u001b[A\n",
            " 44% 110/250 [01:28<01:51,  1.25it/s]\u001b[A\n",
            " 44% 111/250 [01:29<01:51,  1.25it/s]\u001b[A\n",
            " 45% 112/250 [01:29<01:37,  1.41it/s]\u001b[A\n",
            " 45% 113/250 [01:31<02:07,  1.07it/s]\u001b[A\n",
            " 46% 114/250 [01:32<02:13,  1.02it/s]\u001b[A\n",
            " 46% 115/250 [01:33<02:12,  1.02it/s]\u001b[A\n",
            " 46% 116/250 [01:34<02:08,  1.04it/s]\u001b[A\n",
            " 47% 117/250 [01:35<02:04,  1.07it/s]\u001b[A\n",
            " 47% 118/250 [01:36<02:06,  1.04it/s]\u001b[A\n",
            " 48% 119/250 [01:36<01:57,  1.11it/s]\u001b[A\n",
            " 48% 120/250 [01:38<02:10,  1.00s/it]\u001b[A\n",
            " 48% 121/250 [01:39<02:09,  1.01s/it]\u001b[A\n",
            " 49% 122/250 [01:39<01:57,  1.09it/s]\u001b[A\n",
            " 49% 123/250 [01:40<01:50,  1.14it/s]\u001b[A\n",
            " 50% 124/250 [01:41<01:42,  1.23it/s]\u001b[A\n",
            " 50% 125/250 [01:42<01:56,  1.07it/s]\u001b[A\n",
            " 50% 126/250 [01:43<01:50,  1.12it/s]\u001b[A\n",
            " 51% 127/250 [01:45<02:30,  1.22s/it]\u001b[A\n",
            " 51% 128/250 [01:47<02:58,  1.46s/it]\u001b[A\n",
            " 52% 129/250 [01:47<02:25,  1.21s/it]\u001b[A\n",
            " 52% 130/250 [01:49<02:43,  1.36s/it]\u001b[A\n",
            " 52% 131/250 [01:50<02:22,  1.20s/it]\u001b[A\n",
            " 53% 132/250 [01:51<02:17,  1.16s/it]\u001b[A\n",
            " 53% 133/250 [01:52<02:00,  1.03s/it]\u001b[A\n",
            " 54% 134/250 [01:53<02:20,  1.21s/it]\u001b[A\n",
            " 54% 135/250 [01:54<02:07,  1.11s/it]\u001b[A\n",
            " 54% 136/250 [01:55<01:48,  1.05it/s]\u001b[A\n",
            " 55% 137/250 [01:56<01:41,  1.12it/s]\u001b[A\n",
            " 55% 138/250 [01:56<01:32,  1.21it/s]\u001b[A\n",
            " 56% 139/250 [01:57<01:32,  1.20it/s]\u001b[A\n",
            " 56% 140/250 [01:58<01:31,  1.20it/s]\u001b[A\n",
            " 56% 141/250 [01:59<01:23,  1.31it/s]\u001b[A\n",
            " 57% 142/250 [02:00<01:29,  1.21it/s]\u001b[A\n",
            " 57% 143/250 [02:00<01:25,  1.26it/s]\u001b[A\n",
            " 58% 144/250 [02:01<01:26,  1.23it/s]\u001b[A\n",
            " 58% 145/250 [02:02<01:17,  1.36it/s]\u001b[A\n",
            " 58% 146/250 [02:03<01:35,  1.09it/s]\u001b[A\n",
            " 59% 147/250 [02:04<01:27,  1.18it/s]\u001b[A\n",
            " 59% 148/250 [02:05<01:25,  1.19it/s]\u001b[A\n",
            " 60% 149/250 [02:05<01:21,  1.25it/s]\u001b[A\n",
            " 60% 150/250 [02:06<01:28,  1.14it/s]\u001b[A\n",
            " 60% 151/250 [02:07<01:18,  1.26it/s]\u001b[A\n",
            " 61% 152/250 [02:08<01:23,  1.18it/s]\u001b[A\n",
            " 61% 153/250 [02:09<01:18,  1.24it/s]\u001b[A\n",
            " 62% 154/250 [02:09<01:19,  1.20it/s]\u001b[A\n",
            " 62% 155/250 [02:10<01:22,  1.16it/s]\u001b[A\n",
            " 62% 156/250 [02:11<01:23,  1.12it/s]\u001b[A\n",
            " 63% 157/250 [02:13<01:42,  1.10s/it]\u001b[A\n",
            " 63% 158/250 [02:14<01:26,  1.06it/s]\u001b[A\n",
            " 64% 159/250 [02:15<01:36,  1.06s/it]\u001b[A\n",
            " 64% 160/250 [02:16<01:26,  1.04it/s]\u001b[A\n",
            " 64% 161/250 [02:16<01:19,  1.13it/s]\u001b[A\n",
            " 65% 162/250 [02:17<01:09,  1.27it/s]\u001b[A\n",
            " 65% 163/250 [02:18<01:15,  1.16it/s]\u001b[A\n",
            " 66% 164/250 [02:19<01:10,  1.22it/s]\u001b[A\n",
            " 66% 165/250 [02:20<01:11,  1.18it/s]\u001b[A\n",
            " 66% 166/250 [02:20<01:05,  1.28it/s]\u001b[A\n",
            " 67% 167/250 [02:21<01:10,  1.19it/s]\u001b[A\n",
            " 67% 168/250 [02:22<01:03,  1.29it/s]\u001b[A\n",
            " 68% 169/250 [02:22<01:00,  1.33it/s]\u001b[A\n",
            " 68% 170/250 [02:23<01:01,  1.31it/s]\u001b[A\n",
            " 68% 171/250 [02:24<00:57,  1.36it/s]\u001b[A\n",
            " 69% 172/250 [02:25<00:55,  1.41it/s]\u001b[A\n",
            " 69% 173/250 [02:26<01:06,  1.16it/s]\u001b[A\n",
            " 70% 174/250 [02:26<01:01,  1.24it/s]\u001b[A\n",
            " 70% 175/250 [02:27<00:58,  1.29it/s]\u001b[A\n",
            " 70% 176/250 [02:28<00:57,  1.29it/s]\u001b[A\n",
            " 71% 177/250 [02:29<00:54,  1.35it/s]\u001b[A\n",
            " 71% 178/250 [02:29<00:50,  1.43it/s]\u001b[A\n",
            " 72% 179/250 [02:30<00:57,  1.23it/s]\u001b[A\n",
            " 72% 180/250 [02:31<00:52,  1.33it/s]\u001b[A\n",
            " 72% 181/250 [02:32<00:55,  1.23it/s]\u001b[A\n",
            " 73% 182/250 [02:33<00:54,  1.26it/s]\u001b[A\n",
            " 73% 183/250 [02:34<00:59,  1.12it/s]\u001b[A\n",
            " 74% 184/250 [02:35<00:58,  1.13it/s]\u001b[A\n",
            " 74% 185/250 [02:35<00:54,  1.20it/s]\u001b[A\n",
            " 74% 186/250 [02:36<00:49,  1.29it/s]\u001b[A\n",
            " 75% 187/250 [02:37<00:49,  1.26it/s]\u001b[A\n",
            " 75% 188/250 [02:38<01:06,  1.07s/it]\u001b[A\n",
            " 76% 189/250 [02:39<01:01,  1.01s/it]\u001b[A\n",
            " 76% 190/250 [02:40<00:55,  1.09it/s]\u001b[A\n",
            " 76% 191/250 [02:42<01:10,  1.20s/it]\u001b[A\n",
            " 77% 192/250 [02:43<01:01,  1.07s/it]\u001b[A\n",
            " 77% 193/250 [02:44<01:02,  1.10s/it]\u001b[A\n",
            " 78% 194/250 [02:45<01:02,  1.12s/it]\u001b[A\n",
            " 78% 195/250 [02:46<00:59,  1.08s/it]\u001b[A\n",
            " 78% 196/250 [02:47<00:50,  1.06it/s]\u001b[A\n",
            " 79% 197/250 [02:48<00:49,  1.08it/s]\u001b[A\n",
            " 79% 198/250 [02:48<00:45,  1.14it/s]\u001b[A\n",
            " 80% 199/250 [02:49<00:41,  1.22it/s]\u001b[A\n",
            " 80% 200/250 [02:50<00:38,  1.30it/s]\u001b[A\n",
            " 80% 201/250 [02:50<00:33,  1.44it/s]\u001b[A\n",
            " 81% 202/250 [02:51<00:32,  1.47it/s]\u001b[A\n",
            " 81% 203/250 [02:51<00:32,  1.45it/s]\u001b[A\n",
            " 82% 204/250 [02:53<00:45,  1.01it/s]\u001b[A\n",
            " 82% 205/250 [02:54<00:40,  1.10it/s]\u001b[A\n",
            " 82% 206/250 [02:55<00:38,  1.14it/s]\u001b[A\n",
            " 83% 207/250 [02:56<00:44,  1.04s/it]\u001b[A\n",
            " 83% 208/250 [02:57<00:37,  1.13it/s]\u001b[A\n",
            " 84% 209/250 [02:57<00:32,  1.28it/s]\u001b[A\n",
            " 84% 210/250 [02:58<00:35,  1.14it/s]\u001b[A\n",
            " 84% 211/250 [02:59<00:32,  1.21it/s]\u001b[A\n",
            " 85% 212/250 [03:00<00:37,  1.02it/s]\u001b[A\n",
            " 85% 213/250 [03:01<00:33,  1.11it/s]\u001b[A\n",
            " 86% 214/250 [03:02<00:30,  1.19it/s]\u001b[A\n",
            " 86% 215/250 [03:03<00:30,  1.16it/s]\u001b[A\n",
            " 86% 216/250 [03:04<00:31,  1.09it/s]\u001b[A\n",
            " 87% 217/250 [03:05<00:31,  1.03it/s]\u001b[A\n",
            " 87% 218/250 [03:06<00:29,  1.09it/s]\u001b[A\n",
            " 88% 219/250 [03:06<00:27,  1.11it/s]\u001b[A\n",
            " 88% 220/250 [03:07<00:26,  1.14it/s]\u001b[A\n",
            " 88% 221/250 [03:08<00:27,  1.04it/s]\u001b[A\n",
            " 89% 222/250 [03:10<00:28,  1.01s/it]\u001b[A\n",
            " 89% 223/250 [03:10<00:25,  1.08it/s]\u001b[A\n",
            " 90% 224/250 [03:11<00:25,  1.03it/s]\u001b[A\n",
            " 90% 225/250 [03:12<00:23,  1.08it/s]\u001b[A\n",
            " 90% 226/250 [03:13<00:20,  1.17it/s]\u001b[A\n",
            " 91% 227/250 [03:13<00:18,  1.27it/s]\u001b[A\n",
            " 91% 228/250 [03:14<00:17,  1.29it/s]\u001b[A\n",
            " 92% 229/250 [03:15<00:16,  1.25it/s]\u001b[A\n",
            " 92% 230/250 [03:16<00:17,  1.18it/s]\u001b[A\n",
            " 92% 231/250 [03:17<00:16,  1.18it/s]\u001b[A\n",
            " 93% 232/250 [03:18<00:17,  1.04it/s]\u001b[A\n",
            " 93% 233/250 [03:19<00:14,  1.15it/s]\u001b[A\n",
            " 94% 234/250 [03:19<00:12,  1.27it/s]\u001b[A\n",
            " 94% 235/250 [03:20<00:10,  1.39it/s]\u001b[A\n",
            " 94% 236/250 [03:21<00:12,  1.15it/s]\u001b[A\n",
            " 95% 237/250 [03:22<00:10,  1.22it/s]\u001b[A\n",
            " 95% 238/250 [03:23<00:11,  1.04it/s]\u001b[A\n",
            " 96% 239/250 [03:25<00:13,  1.27s/it]\u001b[A\n",
            " 96% 240/250 [03:26<00:12,  1.30s/it]\u001b[A\n",
            " 96% 241/250 [03:27<00:10,  1.12s/it]\u001b[A\n",
            " 97% 242/250 [03:28<00:07,  1.02it/s]\u001b[A\n",
            " 97% 243/250 [03:29<00:07,  1.06s/it]\u001b[A\n",
            " 98% 244/250 [03:30<00:05,  1.06it/s]\u001b[A\n",
            " 98% 245/250 [03:31<00:04,  1.09it/s]\u001b[A\n",
            " 98% 246/250 [03:31<00:03,  1.13it/s]\u001b[A\n",
            " 99% 247/250 [03:32<00:02,  1.25it/s]\u001b[A\n",
            " 99% 248/250 [03:33<00:01,  1.33it/s]\u001b[A\n",
            "100% 249/250 [03:33<00:00,  1.48it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 1.0012447834014893, 'eval_runtime': 215.1836, 'eval_samples_per_second': 9.294, 'eval_steps_per_second': 1.162, 'epoch': 1.06}\n",
            " 53% 200/376 [25:13<22:57,  7.83s/it]\n",
            "100% 250/250 [03:34<00:00,  1.56it/s]\u001b[A\n",
            "                                     \u001b[A/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "{'loss': 1.0038, 'learning_rate': 6.086956521739131e-05, 'epoch': 1.12}\n",
            "{'loss': 0.8479, 'learning_rate': 5.72463768115942e-05, 'epoch': 1.17}\n",
            "{'loss': 0.7137, 'learning_rate': 5.3623188405797106e-05, 'epoch': 1.22}\n",
            "{'loss': 1.0084, 'learning_rate': 5e-05, 'epoch': 1.28}\n",
            "{'loss': 1.0599, 'learning_rate': 4.63768115942029e-05, 'epoch': 1.33}\n",
            "{'loss': 0.9359, 'learning_rate': 4.27536231884058e-05, 'epoch': 1.38}\n",
            "{'loss': 0.717, 'learning_rate': 3.91304347826087e-05, 'epoch': 1.44}\n",
            "{'loss': 0.7089, 'learning_rate': 3.5507246376811596e-05, 'epoch': 1.49}\n",
            "{'loss': 1.1733, 'learning_rate': 3.188405797101449e-05, 'epoch': 1.54}\n",
            "{'loss': 1.0599, 'learning_rate': 2.826086956521739e-05, 'epoch': 1.6}\n",
            "{'loss': 0.867, 'learning_rate': 2.4637681159420292e-05, 'epoch': 1.65}\n",
            "{'loss': 0.6803, 'learning_rate': 2.101449275362319e-05, 'epoch': 1.7}\n",
            "{'loss': 0.8738, 'learning_rate': 1.739130434782609e-05, 'epoch': 1.76}\n",
            "{'loss': 1.1396, 'learning_rate': 1.3768115942028985e-05, 'epoch': 1.81}\n",
            "{'loss': 0.9763, 'learning_rate': 1.0144927536231885e-05, 'epoch': 1.86}\n",
            "{'loss': 0.761, 'learning_rate': 6.521739130434783e-06, 'epoch': 1.91}\n",
            "{'loss': 0.6734, 'learning_rate': 2.898550724637681e-06, 'epoch': 1.97}\n",
            "{'train_runtime': 2550.7185, 'train_samples_per_second': 2.352, 'train_steps_per_second': 0.147, 'train_loss': 1.1050582769069266, 'epoch': 2.0}\n",
            "100% 376/376 [42:30<00:00,  6.78s/it]\n",
            "\n",
            " If there's a warning about missing keys above, please disregard :)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zD2V63OkY6Xh",
        "outputId": "83e5488a-7a2e-44dd-e2d9-12a4ac4a66bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alpaca_data_cleaned_archive.json  lengths.ipynb\n",
            "alpaca_data_gpt4.json\t\t  LICENSE\n",
            "alpaca_data.json\t\t  lora-alpaca-temp\n",
            "DATA_LICENSE\t\t\t  pyproject.toml\n",
            "docker-compose.yml\t\t  README.md\n",
            "Dockerfile\t\t\t  requirements.txt\n",
            "export_hf_checkpoint.py\t\t  temp.json\n",
            "export_state_dict_checkpoint.py   templates\n",
            "finetune.py\t\t\t  utils\n",
            "generate.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3RhdoiasY9gH",
        "outputId": "e571e7d3-23f4-4481-cb22-ee407c3e6d78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/alpaca-lora'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/alpaca-lora"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZctZITYSZdBy",
        "outputId": "4614a7df-eabb-4358-8cd0-522cb9e1108f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/alpaca-lora\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "path = \"/content/gdrive/MyDrive/mysafefolder\" ## THIS IS THE PATH WHERE THE FINETUNED MODEL WILL BE STORED IN YOUR GOOGLE DRIVE\n",
        "os.mkdir(path)"
      ],
      "metadata": {
        "id": "m4kCReSTbXEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r ../alpaca-lora/ /content/gdrive/MyDrive/mysafefolder ## COPYING THE MODEL WEIGHTS TO THE PATH"
      ],
      "metadata": {
        "id": "xVkhNkDzbfUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/MyDrive/mysafefolder/alpaca-lora"
      ],
      "metadata": {
        "id": "zbZs2M1eRaDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***BELOW IS THE COMMAND FOR GENERATING THE UI FOR DOING INFERENCE FROM OUR FINETUNED MODEL***\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "oDT5RP1hR5RI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python generate.py \\\n",
        "    --base_model 'openlm-research/open_llama_3b_v2' \\\n",
        "    --lora_weights 'lora-alpaca-temp' \\\n",
        "    --share_gradio True"
      ],
      "metadata": {
        "id": "jvNIOtu1Rmv2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}